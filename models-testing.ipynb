{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accf9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97d15e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 2001 # Number of time points to use from each CSV\n",
    "SIGNAL_COL = 'F3_1000Hz'\n",
    "SENSOR_DIR = \"C:\\\\DumbStuff\\\\epf study\\\\Meta-Elasto\\\\els\\\\meta\\\\Elastography_rawdata\\\\oldcode\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a3672b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre = pd.read_csv(\"label-pre.csv\")\n",
    "df_post = pd.read_csv(\"label-post.csv\")\n",
    "df_fup = pd.read_csv(\"label-fup.csv\")\n",
    "\n",
    "df_pre['Time'] = 'PRE'\n",
    "df_post['Time'] = 'POST'\n",
    "df_fup['Time'] = 'FOLLOWUP'\n",
    "\n",
    "df_clinical = pd.concat([df_pre, df_post, df_fup]).reset_index(drop=True)\n",
    "\n",
    "df_mapping = pd.read_excel(\"meta/measured_with_elastograph_patients.xlsx\")\n",
    "df_mapping.columns = df_mapping.columns.str.strip()\n",
    "\n",
    "df_master = pd.merge(df_mapping, df_clinical, on=['ID', 'Time'], how='inner')\n",
    "df_master = df_master.dropna(subset=['Target_Metabolic_Disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da4363dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalDataset(Dataset):\n",
    "    def __init__(self, dataframe, sensor_dir, transform_meta=None):\n",
    "        self.df = dataframe\n",
    "        self.sensor_dir = sensor_dir\n",
    "        self.transform_meta = transform_meta\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        p_num = str(int(row['N_PACIENT'])).zfill(4)\n",
    "        \n",
    "        # Load Signal (Pick the first file found for this patient number)\n",
    "        # In a more advanced version, you could load ALL reps/angles as separate samples\n",
    "        file_path = glob.glob(os.path.join(self.sensor_dir, f\"in_test_{p_num}_*.csv\"))[0]\n",
    "        sig_df = pd.read_csv(file_path)\n",
    "        signal = sig_df[SIGNAL_COL].fillna(0).values[:MAX_LEN]\n",
    "        \n",
    "        # Pad signal if it's too short\n",
    "        if len(signal) < MAX_LEN:\n",
    "            signal = np.pad(signal, (0, MAX_LEN - len(signal)), 'constant')\n",
    "        \n",
    "        # Metadata Features\n",
    "        meta_feats = np.array([row['Sex'], row['Age'], row['Waist_Circum_mean']], dtype=np.float32)\n",
    "        \n",
    "        label = int(row['Target_Metabolic_Disease'])\n",
    "        \n",
    "        return (torch.tensor(signal, dtype=torch.float32).unsqueeze(0), # [1, 2000]\n",
    "                torch.tensor(meta_feats, dtype=torch.float32), \n",
    "                torch.tensor(label, dtype=torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2315bfd",
   "metadata": {},
   "source": [
    "# Multi Modal CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfe8d8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalCNN(nn.Module):\n",
    "    def __init__(self, num_meta_features):\n",
    "        super(MultiModalCNN, self).__init__()\n",
    "        \n",
    "        # --- Branch 1: The Signal Brain (1D CNN) ---\n",
    "        self.signal_branch = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4), # Reduces 2000 -> 500\n",
    "            \n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4), # Reduces 500 -> 125\n",
    "            \n",
    "            nn.AdaptiveAvgPool1d(1) # Flatten to [64]\n",
    "        )\n",
    "        \n",
    "        # --- Branch 2: Metadata branch ---\n",
    "        self.meta_branch = nn.Sequential(\n",
    "            nn.Linear(num_meta_features, 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # --- Branch 3: Fusion ---\n",
    "        # CNN output (64) + Meta output (16) = 80\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 + 16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 2) # Binary: Healthy vs Disease\n",
    "        )\n",
    "\n",
    "    def forward(self, signal, meta):\n",
    "        sig_out = self.signal_branch(signal).squeeze(-1)\n",
    "        meta_out = self.meta_branch(meta)\n",
    "        \n",
    "        # Concatenate!\n",
    "        combined = torch.cat((sig_out, meta_out), dim=1)\n",
    "        return self.classifier(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ddd1b2",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29cc6023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Fold 1 ---\n",
      "Fold 1 Accuracy: 44.44%\n",
      "\n",
      "--- Training Fold 2 ---\n",
      "Fold 2 Accuracy: 40.74%\n",
      "\n",
      "--- Training Fold 3 ---\n",
      "Fold 3 Accuracy: 44.44%\n",
      "\n",
      "--- Training Fold 4 ---\n",
      "Fold 4 Accuracy: 37.04%\n",
      "\n",
      "--- Training Fold 5 ---\n",
      "Fold 5 Accuracy: 57.69%\n",
      "\n",
      "Average Multi-Modal Accuracy: 44.87%\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "groups = df_master['ID'].values\n",
    "X_indices = np.arange(len(df_master))\n",
    "Y_labels = df_master['Target_Metabolic_Disease'].values\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(X_indices, Y_labels, groups)):\n",
    "    print(f\"\\n--- Training Fold {fold+1} ---\")\n",
    "    \n",
    "    train_ds = MultiModalDataset(df_master.iloc[train_idx], SENSOR_DIR)\n",
    "    val_ds = MultiModalDataset(df_master.iloc[val_idx], SENSOR_DIR)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=16)\n",
    "    \n",
    "    model = MultiModalCNN(num_meta_features=3).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Simple training loop\n",
    "    for epoch in range(20):\n",
    "        model.train()\n",
    "        for sig, meta, lbl in train_loader:\n",
    "            sig, meta, lbl = sig.to(device), meta.to(device), lbl.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sig, meta)\n",
    "            loss = criterion(outputs, lbl)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for sig, meta, lbl in val_loader:\n",
    "            sig, meta, lbl = sig.to(device), meta.to(device), lbl.to(device)\n",
    "            outputs = model(sig, meta)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += lbl.size(0)\n",
    "            correct += (predicted == lbl).sum().item()\n",
    "            \n",
    "    acc = 100 * correct / total\n",
    "    fold_results.append(acc)\n",
    "    print(f\"Fold {fold+1} Accuracy: {acc:.2f}%\")\n",
    "\n",
    "print(f\"\\nAverage Multi-Modal Accuracy: {np.mean(fold_results):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d14c25",
   "metadata": {},
   "source": [
    "# New I guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "956142e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data merged. Unique Patients: 104. Total visit records: 134\n",
      "\n",
      "=== FOLD 1 ===\n",
      "Indexing all sensor files for augmentation...\n",
      "Total augmented samples (files): 1237\n",
      "Indexing all sensor files for augmentation...\n",
      "Total augmented samples (files): 314\n",
      "Fold Accuracy: 63.69%\n",
      "\n",
      "=== FOLD 2 ===\n",
      "Indexing all sensor files for augmentation...\n",
      "Total augmented samples (files): 1231\n",
      "Indexing all sensor files for augmentation...\n",
      "Total augmented samples (files): 320\n",
      "Fold Accuracy: 46.56%\n",
      "\n",
      "=== FOLD 3 ===\n",
      "Indexing all sensor files for augmentation...\n",
      "Total augmented samples (files): 1236\n",
      "Indexing all sensor files for augmentation...\n",
      "Total augmented samples (files): 315\n",
      "Fold Accuracy: 60.95%\n",
      "\n",
      "=== FOLD 4 ===\n",
      "Indexing all sensor files for augmentation...\n",
      "Total augmented samples (files): 1249\n",
      "Indexing all sensor files for augmentation...\n",
      "Total augmented samples (files): 302\n",
      "Fold Accuracy: 59.93%\n",
      "\n",
      "=== FOLD 5 ===\n",
      "Indexing all sensor files for augmentation...\n",
      "Total augmented samples (files): 1251\n",
      "Indexing all sensor files for augmentation...\n",
      "Total augmented samples (files): 300\n",
      "Fold Accuracy: 74.33%\n",
      "\n",
      "Final Average Multi-Modal Accuracy: 61.10%\n"
     ]
    }
   ],
   "source": [
    "SENSOR_DIR = \"C:\\\\DumbStuff\\\\epf study\\\\Meta-Elasto\\\\els\\\\meta\\\\Elastography_rawdata\\\\oldcode\\\\\"\n",
    "MAX_LEN = 2000  # Number of data points per signal\n",
    "\n",
    "# Load Clinical Labels\n",
    "df_pre = pd.read_csv(\"label-pre.csv\")\n",
    "df_pre['Time'] = 'PRE'\n",
    "\n",
    "df_post = pd.read_csv(\"label-post.csv\")\n",
    "df_post['Time'] = 'POST'\n",
    "\n",
    "df_fup = pd.read_csv(\"label-fup.csv\")\n",
    "df_fup['Time'] = 'FOLLOWUP'\n",
    "\n",
    "df_clinical = pd.concat([df_pre, df_post, df_fup], axis=0, ignore_index=True)\n",
    "\n",
    "# Load Mapping Table (Rosetta Stone)\n",
    "df_mapping = pd.read_excel(\"meta/measured_with_elastograph_patients.xlsx\")\n",
    "df_mapping.columns = df_mapping.columns.str.strip()\n",
    "\n",
    "# Merge info\n",
    "df_master = pd.merge(df_mapping, df_clinical, on=['ID', 'Time'], how='inner')\n",
    "df_master = df_master.dropna(subset=['Target_Metabolic_Disease', 'Sex', 'Age', 'Waist_Circum_mean'])\n",
    "\n",
    "# Global Scaling of Metadata (Prevents Waist > Age > Sex bias)\n",
    "meta_cols = ['Sex', 'Age', 'Waist_Circum_mean']\n",
    "scaler = StandardScaler()\n",
    "df_master[meta_cols] = scaler.fit_transform(df_master[meta_cols])\n",
    "\n",
    "print(f\"Data merged. Unique Patients: {df_master['ID'].nunique()}. Total visit records: {len(df_master)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. DATASET CLASS (Augmented: Uses ALL files)\n",
    "# ==========================================\n",
    "class MetabolicDataset(Dataset):\n",
    "    def __init__(self, dataframe, sensor_dir, max_len=2000):\n",
    "        self.max_len = max_len\n",
    "        self.all_samples = []\n",
    "        \n",
    "        print(\"Indexing all sensor files for augmentation...\")\n",
    "        for _, row in dataframe.iterrows():\n",
    "            p_num_str = str(int(row['N_PACIENT'])).zfill(4)\n",
    "            # Find ALL repetitions/angles for this specific patient visit\n",
    "            patient_files = glob.glob(os.path.join(sensor_dir, f\"in_test_{p_num_str}_*.csv\"))\n",
    "            \n",
    "            for f in patient_files:\n",
    "                self.all_samples.append({\n",
    "                    'filepath': f,\n",
    "                    'meta': torch.tensor([row['Sex'], row['Age'], row['Waist_Circum_mean']], dtype=torch.float32),\n",
    "                    'label': int(row['Target_Metabolic_Disease']),\n",
    "                    'id': row['ID'] # Needed for GroupKFold\n",
    "                })\n",
    "        print(f\"Total augmented samples (files): {len(self.all_samples)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.all_samples[idx]\n",
    "        \n",
    "        # Load Signal\n",
    "        df_sig = pd.read_csv(sample['filepath'])\n",
    "        # Take first column (usually F1_2000Hz), clean nans\n",
    "        signal = df_sig.iloc[:, 2].fillna(0).values[:self.max_len]\n",
    "        \n",
    "        # Pad if short\n",
    "        if len(signal) < self.max_len:\n",
    "            signal = np.pad(signal, (0, self.max_len - len(signal)), 'constant')\n",
    "        \n",
    "        # SIGNAL NORMALIZATION (Per sample)\n",
    "        mean = np.mean(signal)\n",
    "        std = np.std(signal) + 1e-8\n",
    "        signal = (signal - mean) / std\n",
    "        \n",
    "        return (torch.tensor(signal, dtype=torch.float32).unsqueeze(0), \n",
    "                sample['meta'], \n",
    "                torch.tensor(sample['label'], dtype=torch.long))\n",
    "\n",
    "# ==========================================\n",
    "# 3. MULTI-MODAL CNN ARCHITECTURE\n",
    "# ==========================================\n",
    "class MultiModalCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiModalCNN, self).__init__()\n",
    "        \n",
    "        # Branch 1: Signal Processing\n",
    "        self.signal_branch = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=15, stride=2, padding=7),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool1d(4),\n",
    "            \n",
    "            nn.Conv1d(16, 32, kernel_size=7, stride=1, padding=3),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        \n",
    "        # Branch 2: Clinical Fusion\n",
    "        # 32 (from CNN) + 3 (Sex, Age, Waist) = 35\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32 + 3, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4), # Critical to stop overfitting\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, signal, meta):\n",
    "        sig_out = self.signal_branch(signal).squeeze(-1)\n",
    "        combined = torch.cat((sig_out, meta), dim=1)\n",
    "        return self.classifier(combined)\n",
    "\n",
    "# ==========================================\n",
    "# 4. TRAINING WITH GROUP-K-FOLD\n",
    "# ==========================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Determine Class Weights and explicitly cast to FLOAT32\n",
    "counts = df_master['Target_Metabolic_Disease'].value_counts().sort_index()\n",
    "# We use .values to ensure we get the numbers correctly\n",
    "weights = 1.0 / counts.values\n",
    "class_weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "ids = df_master['ID'].values\n",
    "fold_accs = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(df_master, groups=ids)):\n",
    "    print(f\"\\n=== FOLD {fold+1} ===\")\n",
    "    \n",
    "    train_ds = MetabolicDataset(df_master.iloc[train_idx], SENSOR_DIR)\n",
    "    val_ds = MetabolicDataset(df_master.iloc[val_idx], SENSOR_DIR)\n",
    "    \n",
    "    # Using smaller batch size can sometimes help stability on small datasets\n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=32)\n",
    "    \n",
    "    model = MultiModalCNN().to(device)\n",
    "    \n",
    "    # Ensure model parameters are float32\n",
    "    model = model.float() \n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4)\n",
    "    \n",
    "    # The weight here must be the same type as the model output (Float32)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    # Training Loop\n",
    "    for epoch in range(30):\n",
    "        model.train()\n",
    "        for sig, meta, lbl in train_loader:\n",
    "            # Explicitly move to device and ensure float type\n",
    "            sig = sig.to(device).float()\n",
    "            meta = meta.to(device).float()\n",
    "            lbl = lbl.to(device).long() # Labels must be Long for CrossEntropy\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sig, meta)\n",
    "            \n",
    "            loss = criterion(outputs, lbl)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    with torch.no_grad():\n",
    "        for sig, meta, lbl in val_loader:\n",
    "            sig = sig.to(device).float()\n",
    "            meta = meta.to(device).float()\n",
    "            lbl = lbl.to(device).long()\n",
    "            \n",
    "            outputs = model(sig, meta)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_true.extend(lbl.cpu().numpy())\n",
    "            \n",
    "    acc = accuracy_score(all_true, all_preds)\n",
    "    fold_accs.append(acc)\n",
    "    print(f\"Fold Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nFinal Average Multi-Modal Accuracy: {np.mean(fold_accs)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be136ca4",
   "metadata": {},
   "source": [
    "# More"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ce05522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FOLD 1 ===\n",
      "Fold Accuracy: 55.41%\n",
      "\n",
      "=== FOLD 2 ===\n",
      "Fold Accuracy: 60.94%\n",
      "\n",
      "=== FOLD 3 ===\n",
      "Fold Accuracy: 68.25%\n",
      "\n",
      "=== FOLD 4 ===\n",
      "Fold Accuracy: 51.66%\n",
      "\n",
      "=== FOLD 5 ===\n",
      "Fold Accuracy: 67.00%\n",
      "\n",
      "Final Average PSD-CNN Accuracy: 60.65%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import signal as scipy_signal\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & DATA MERGING (Same as before)\n",
    "# ==========================================\n",
    "SENSOR_DIR = \"C:\\\\DumbStuff\\\\epf study\\\\Meta-Elasto\\\\els\\\\meta\\\\Elastography_rawdata\\\\oldcode\\\\\"\n",
    "FS = 2000  # Sampling frequency\n",
    "\n",
    "# Load and Merge Clinical (ensure 'Time' is added as discussed previously)\n",
    "df_pre = pd.read_csv(\"label-pre.csv\"); df_pre['Time'] = 'PRE'\n",
    "df_post = pd.read_csv(\"label-post.csv\"); df_post['Time'] = 'POST'\n",
    "df_fup = pd.read_csv(\"label-fup.csv\"); df_fup['Time'] = 'FOLLOWUP'\n",
    "df_clinical = pd.concat([df_pre, df_post, df_fup], axis=0, ignore_index=True)\n",
    "\n",
    "df_mapping = pd.read_excel(\"meta/measured_with_elastograph_patients.xlsx\")\n",
    "df_mapping.columns = df_mapping.columns.str.strip()\n",
    "\n",
    "df_master = pd.merge(df_mapping, df_clinical, on=['ID', 'Time'], how='inner')\n",
    "df_master = df_master.dropna(subset=['Target_Metabolic_Disease', 'Sex', 'Age', 'Waist_Circum_mean'])\n",
    "\n",
    "# Scaling\n",
    "meta_cols = ['Sex', 'Age', 'Waist_Circum_mean']\n",
    "scaler = StandardScaler()\n",
    "df_master[meta_cols] = scaler.fit_transform(df_master[meta_cols])\n",
    "\n",
    "# ==========================================\n",
    "# 2. ADVANCED DATASET (Frequency Domain)\n",
    "# ==========================================\n",
    "class MetabolicPSDDataset(Dataset):\n",
    "    def __init__(self, dataframe, sensor_dir):\n",
    "        self.sensor_dir = sensor_dir\n",
    "        self.all_samples = []\n",
    "        \n",
    "        for _, row in dataframe.iterrows():\n",
    "            p_num_str = str(int(row['N_PACIENT'])).zfill(4)\n",
    "            patient_files = glob.glob(os.path.join(sensor_dir, f\"in_test_{p_num_str}_*.csv\"))\n",
    "            for f in patient_files:\n",
    "                self.all_samples.append({\n",
    "                    'filepath': f,\n",
    "                    'meta': torch.tensor([row['Sex'], row['Age'], row['Waist_Circum_mean']], dtype=torch.float32),\n",
    "                    'label': int(row['Target_Metabolic_Disease']),\n",
    "                    'id': row['ID']\n",
    "                })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.all_samples[idx]\n",
    "        df_sig = pd.read_csv(sample['filepath'])\n",
    "        raw_signal = df_sig.iloc[:, 2].fillna(0).values\n",
    "        \n",
    "        # A. BANDPASS FILTER (Remove noise below 10Hz and above 400Hz)\n",
    "        b, a = scipy_signal.butter(4, [10, 400], btype='bandpass', fs=FS)\n",
    "        filt_signal = scipy_signal.filtfilt(b, a, raw_signal)\n",
    "        \n",
    "        # B. WELCH PSD (Convert to Frequency Domain)\n",
    "        # This gives us a 129-point \"signature\" of the signal's frequencies\n",
    "        freqs, psd = scipy_signal.welch(filt_signal, fs=FS, nperseg=256)\n",
    "        \n",
    "        # C. LOG TRANSFORM (Standard for frequency data)\n",
    "        psd_log = np.log10(psd + 1e-10)\n",
    "        \n",
    "        # D. NORMALIZATION\n",
    "        psd_norm = (psd_log - np.mean(psd_log)) / (np.std(psd_log) + 1e-8)\n",
    "        \n",
    "        return (torch.tensor(psd_norm, dtype=torch.float32).unsqueeze(0), \n",
    "                sample['meta'], \n",
    "                torch.tensor(sample['label'], dtype=torch.long))\n",
    "\n",
    "# ==========================================\n",
    "# 3. FREQUENCY-CONV NET\n",
    "# ==========================================\n",
    "class FrequencyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FrequencyCNN, self).__init__()\n",
    "        # Input size is [1, 129]\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32 + 3, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(16, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, meta):\n",
    "        x = self.conv_block(x).squeeze(-1)\n",
    "        combined = torch.cat((x, meta), dim=1)\n",
    "        return self.classifier(combined)\n",
    "\n",
    "# ==========================================\n",
    "# 4. TRAINING LOOP\n",
    "# ==========================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "counts = df_master['Target_Metabolic_Disease'].value_counts().sort_index()\n",
    "class_weights = torch.tensor([1.0/counts[0], 1.0/counts[1]], dtype=torch.float32).to(device)\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "ids = df_master['ID'].values\n",
    "fold_accs = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(df_master, groups=ids)):\n",
    "    print(f\"\\n=== FOLD {fold+1} ===\")\n",
    "    train_ds = MetabolicPSDDataset(df_master.iloc[train_idx], SENSOR_DIR)\n",
    "    val_ds = MetabolicPSDDataset(df_master.iloc[val_idx], SENSOR_DIR)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=32)\n",
    "    \n",
    "    model = FrequencyCNN().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    for epoch in range(50): # Frequency data converges slower but more stably\n",
    "        model.train()\n",
    "        for sig, meta, lbl in train_loader:\n",
    "            sig, meta, lbl = sig.to(device), meta.to(device), lbl.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(sig, meta), lbl)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    model.eval()\n",
    "    all_preds, all_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for sig, meta, lbl in val_loader:\n",
    "            outputs = model(sig.to(device), meta.to(device))\n",
    "            all_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "            all_true.extend(lbl.cpu().numpy())\n",
    "            \n",
    "    acc = accuracy_score(all_true, all_preds)\n",
    "    fold_accs.append(acc)\n",
    "    print(f\"Fold Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nFinal Average PSD-CNN Accuracy: {np.mean(fold_accs)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6b063ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:88: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:88: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\ameyd\\AppData\\Local\\Temp\\ipykernel_3028\\2703792085.py:88: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  signal = df_sig.filter(regex='^F\\d+').fillna(0).values.T # Transpose to [Channels, Time]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Ready. Total visit records: 134\n",
      "\n",
      "=== STARTING FOLD 1 ===\n",
      "Total files indexed for training/test: 1237\n",
      "Total files indexed for training/test: 314\n",
      "Fold 1 Accuracy: 58.92%\n",
      "\n",
      "=== STARTING FOLD 2 ===\n",
      "Total files indexed for training/test: 1231\n",
      "Total files indexed for training/test: 320\n",
      "Fold 2 Accuracy: 53.44%\n",
      "\n",
      "=== STARTING FOLD 3 ===\n",
      "Total files indexed for training/test: 1236\n",
      "Total files indexed for training/test: 315\n",
      "Fold 3 Accuracy: 64.76%\n",
      "\n",
      "=== STARTING FOLD 4 ===\n",
      "Total files indexed for training/test: 1249\n",
      "Total files indexed for training/test: 302\n",
      "Fold 4 Accuracy: 58.28%\n",
      "\n",
      "=== STARTING FOLD 5 ===\n",
      "Total files indexed for training/test: 1251\n",
      "Total files indexed for training/test: 300\n",
      "Fold 5 Accuracy: 66.00%\n",
      "\n",
      "Final Average Multi-Channel Accuracy: 60.28%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & PATHS\n",
    "# ==========================================\n",
    "# Adjust these paths to your computer\n",
    "SENSOR_DIR = \"C:\\\\DumbStuff\\\\epf study\\\\Meta-Elasto\\\\els\\\\meta\\\\Elastography_rawdata\\\\oldcode\\\\\"\n",
    "MAPPING_PATH = \"meta/measured_with_elastograph_patients.xlsx\"\n",
    "MAX_LEN = 2000  # We will take 2000 points from every file\n",
    "NUM_CHANNELS = 18 # We will use all columns F1 through F18\n",
    "\n",
    "# ==========================================\n",
    "# 2. DATA MERGING & CLEANING\n",
    "# ==========================================\n",
    "# Load clinical files and add the 'Time' tag to match the mapping\n",
    "df_pre = pd.read_csv(\"label-pre.csv\")\n",
    "df_pre['Time'] = 'PRE'\n",
    "\n",
    "df_post = pd.read_csv(\"label-post.csv\")\n",
    "df_post['Time'] = 'POST'\n",
    "\n",
    "df_fup = pd.read_csv(\"label-fup.csv\")\n",
    "df_fup['Time'] = 'FOLLOWUP'\n",
    "\n",
    "df_clinical = pd.concat([df_pre, df_post, df_fup], axis=0, ignore_index=True)\n",
    "\n",
    "# Load the mapping table (Rosetta Stone)\n",
    "df_mapping = pd.read_excel(MAPPING_PATH)\n",
    "df_mapping.columns = df_mapping.columns.str.strip()\n",
    "\n",
    "# Merge clinical data with mapping table\n",
    "df_master = pd.merge(df_mapping, df_clinical, on=['ID', 'Time'], how='inner')\n",
    "\n",
    "# Drop rows that are missing the label or the clinical features\n",
    "df_master = df_master.dropna(subset=['Target_Metabolic_Disease', 'Sex', 'Age', 'Waist_Circum_mean'])\n",
    "\n",
    "# Standardize clinical features (Age, Sex, Waist) so they are on the same scale\n",
    "meta_cols = ['Sex', 'Age', 'Waist_Circum_mean']\n",
    "scaler = StandardScaler()\n",
    "df_master[meta_cols] = scaler.fit_transform(df_master[meta_cols])\n",
    "\n",
    "print(f\"Dataset Ready. Total visit records: {len(df_master)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. MULTI-CHANNEL DATASET CLASS\n",
    "# ==========================================\n",
    "class MetabolicWholeSignalDataset(Dataset):\n",
    "    def __init__(self, dataframe, sensor_dir, max_len=2000):\n",
    "        self.max_len = max_len\n",
    "        self.sensor_dir = sensor_dir\n",
    "        self.samples = []\n",
    "        \n",
    "        # We index every single file for every patient visit\n",
    "        for _, row in dataframe.iterrows():\n",
    "            p_num_str = str(int(row['N_PACIENT'])).zfill(4)\n",
    "            # Find all repetitions/angles for this patient session\n",
    "            files = glob.glob(os.path.join(self.sensor_dir, f\"in_test_{p_num_str}_*.csv\"))\n",
    "            \n",
    "            for f in files:\n",
    "                self.samples.append({\n",
    "                    'file': f,\n",
    "                    'meta': torch.tensor([row['Sex'], row['Age'], row['Waist_Circum_mean']], dtype=torch.float32),\n",
    "                    'label': int(row['Target_Metabolic_Disease']),\n",
    "                    'id': row['ID'] # To keep patient reps together in Fold\n",
    "                })\n",
    "        print(f\"Total files indexed for training/test: {len(self.samples)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # Load the CSV\n",
    "        df_sig = pd.read_csv(sample['file'])\n",
    "        \n",
    "        # SELECT ALL 18 CHANNELS (F1 to F18)\n",
    "        # We use regex to grab all columns starting with F\n",
    "        signal = df_sig.filter(regex='^F\\d+').fillna(0).values.T # Transpose to [Channels, Time]\n",
    "        \n",
    "        # Fix Length\n",
    "        if signal.shape[1] > self.max_len:\n",
    "            signal = signal[:, :self.max_len]\n",
    "        else:\n",
    "            pad_width = self.max_len - signal.shape[1]\n",
    "            signal = np.pad(signal, ((0,0), (0, pad_width)), mode='constant')\n",
    "            \n",
    "        # NORMALIZE SIGNAL (Per channel)\n",
    "        for i in range(signal.shape[0]):\n",
    "            std = np.std(signal[i, :]) + 1e-8\n",
    "            signal[i, :] = (signal[i, :] - np.mean(signal[i, :])) / std\n",
    "            \n",
    "        return (torch.tensor(signal, dtype=torch.float32), \n",
    "                sample['meta'], \n",
    "                torch.tensor(sample['label'], dtype=torch.long))\n",
    "\n",
    "# ==========================================\n",
    "# 4. MULTI-CHANNEL CNN MODEL\n",
    "# ==========================================\n",
    "class MultiChannelCNN(nn.Module):\n",
    "    def __init__(self, in_channels=18):\n",
    "        super(MultiChannelCNN, self).__init__()\n",
    "        \n",
    "        # Branch 1: The Signal Brain (looks at 18 frequencies)\n",
    "        self.signal_branch = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, 32, kernel_size=11, stride=2, padding=5),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            \n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1) # Compress time to 1 feature per filter\n",
    "        )\n",
    "        \n",
    "        # Branch 2: The Fusion (Signal + Metadata)\n",
    "        # 64 features from signal + 3 features from clinical (Age, Sex, Waist)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 + 3, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, signal, meta):\n",
    "        sig_features = self.signal_branch(signal).squeeze(-1)\n",
    "        combined = torch.cat((sig_features, meta), dim=1)\n",
    "        return self.classifier(combined)\n",
    "\n",
    "# ==========================================\n",
    "# 5. TRAINING ENGINE (GroupKFold)\n",
    "# ==========================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Calculate weights to handle class imbalance\n",
    "counts = df_master['Target_Metabolic_Disease'].value_counts().sort_index()\n",
    "weights = 1.0 / counts.values\n",
    "class_weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "patient_ids = df_master['ID'].values\n",
    "fold_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(df_master, groups=patient_ids)):\n",
    "    print(f\"\\n=== STARTING FOLD {fold+1} ===\")\n",
    "    \n",
    "    train_ds = MetabolicWholeSignalDataset(df_master.iloc[train_idx], SENSOR_DIR)\n",
    "    val_ds = MetabolicWholeSignalDataset(df_master.iloc[val_idx], SENSOR_DIR)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=16)\n",
    "    \n",
    "    model = MultiChannelCNN(in_channels=NUM_CHANNELS).to(device).float()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    # Training Loop\n",
    "    for epoch in range(25):\n",
    "        model.train()\n",
    "        for sig, meta, lbl in train_loader:\n",
    "            sig, meta, lbl = sig.to(device).float(), meta.to(device).float(), lbl.to(device).long()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sig, meta)\n",
    "            loss = criterion(outputs, lbl)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    all_preds, all_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for sig, meta, lbl in val_loader:\n",
    "            outputs = model(sig.to(device).float(), meta.to(device).float())\n",
    "            all_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "            all_true.extend(lbl.cpu().numpy())\n",
    "            \n",
    "    acc = accuracy_score(all_true, all_preds)\n",
    "    fold_scores.append(acc)\n",
    "    print(f\"Fold {fold+1} Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nFinal Average Multi-Channel Accuracy: {np.mean(fold_scores)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb97b91",
   "metadata": {},
   "source": [
    "# TCN Finally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52e1822f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:64: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:64: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\ameyd\\AppData\\Local\\Temp\\ipykernel_24912\\2889140447.py:64: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  signal = df_sig.filter(regex='^F\\d+').fillna(0).values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Fold 1 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.5133 - loss: 0.7598 - val_accuracy: 0.5987 - val_loss: 0.7090\n",
      "Epoch 2/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.6079 - loss: 0.6646 - val_accuracy: 0.4745 - val_loss: 0.7008\n",
      "Epoch 3/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.6297 - loss: 0.6441 - val_accuracy: 0.6306 - val_loss: 0.7443\n",
      "Epoch 4/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6758 - loss: 0.6277 - val_accuracy: 0.6465 - val_loss: 0.7553\n",
      "Epoch 5/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.6896 - loss: 0.6078 - val_accuracy: 0.5924 - val_loss: 0.7546\n",
      "Epoch 6/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.6960 - loss: 0.6010 - val_accuracy: 0.5955 - val_loss: 0.7691\n",
      "Epoch 7/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.7162 - loss: 0.5917 - val_accuracy: 0.5159 - val_loss: 0.7759\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Fold 1 Accuracy: 47.45%\n",
      "\n",
      "--- Training Fold 2 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.5134 - loss: 0.7279 - val_accuracy: 0.6562 - val_loss: 0.6798\n",
      "Epoch 2/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.5500 - loss: 0.6855 - val_accuracy: 0.6687 - val_loss: 0.6760\n",
      "Epoch 3/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.5768 - loss: 0.6737 - val_accuracy: 0.6781 - val_loss: 0.6759\n",
      "Epoch 4/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5955 - loss: 0.6634 - val_accuracy: 0.5969 - val_loss: 0.6790\n",
      "Epoch 5/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6499 - loss: 0.6453 - val_accuracy: 0.5750 - val_loss: 0.6771\n",
      "Epoch 6/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6515 - loss: 0.6362 - val_accuracy: 0.6000 - val_loss: 0.6645\n",
      "Epoch 7/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6686 - loss: 0.6246 - val_accuracy: 0.5906 - val_loss: 0.6876\n",
      "Epoch 8/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.6864 - loss: 0.6085 - val_accuracy: 0.5781 - val_loss: 0.6859\n",
      "Epoch 9/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6905 - loss: 0.6092 - val_accuracy: 0.5469 - val_loss: 0.7009\n",
      "Epoch 10/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7051 - loss: 0.6040 - val_accuracy: 0.5781 - val_loss: 0.6853\n",
      "Epoch 11/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7051 - loss: 0.5883 - val_accuracy: 0.5781 - val_loss: 0.7025\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Fold 2 Accuracy: 60.00%\n",
      "\n",
      "--- Training Fold 3 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.5065 - loss: 0.7386 - val_accuracy: 0.3492 - val_loss: 0.7077\n",
      "Epoch 2/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5469 - loss: 0.6843 - val_accuracy: 0.5810 - val_loss: 0.6898\n",
      "Epoch 3/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5623 - loss: 0.6755 - val_accuracy: 0.3429 - val_loss: 0.7248\n",
      "Epoch 4/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5850 - loss: 0.6673 - val_accuracy: 0.6857 - val_loss: 0.6640\n",
      "Epoch 5/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6181 - loss: 0.6577 - val_accuracy: 0.6032 - val_loss: 0.7123\n",
      "Epoch 6/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6294 - loss: 0.6450 - val_accuracy: 0.6190 - val_loss: 0.6928\n",
      "Epoch 7/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6440 - loss: 0.6396 - val_accuracy: 0.6159 - val_loss: 0.6743\n",
      "Epoch 8/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6570 - loss: 0.6389 - val_accuracy: 0.7111 - val_loss: 0.6529\n",
      "Epoch 9/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6659 - loss: 0.6234 - val_accuracy: 0.6413 - val_loss: 0.6538\n",
      "Epoch 10/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6828 - loss: 0.6164 - val_accuracy: 0.6127 - val_loss: 0.6601\n",
      "Epoch 11/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6861 - loss: 0.6106 - val_accuracy: 0.6571 - val_loss: 0.6392\n",
      "Epoch 12/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6934 - loss: 0.6040 - val_accuracy: 0.6635 - val_loss: 0.6535\n",
      "Epoch 13/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7079 - loss: 0.5990 - val_accuracy: 0.6381 - val_loss: 0.6477\n",
      "Epoch 14/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6974 - loss: 0.5958 - val_accuracy: 0.6286 - val_loss: 0.6767\n",
      "Epoch 15/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7071 - loss: 0.5878 - val_accuracy: 0.6667 - val_loss: 0.6458\n",
      "Epoch 16/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7241 - loss: 0.5748 - val_accuracy: 0.6254 - val_loss: 0.6760\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Fold 3 Accuracy: 65.71%\n",
      "\n",
      "--- Training Fold 4 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.5076 - loss: 0.7346 - val_accuracy: 0.3907 - val_loss: 0.7120\n",
      "Epoch 2/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.5564 - loss: 0.6847 - val_accuracy: 0.4801 - val_loss: 0.6936\n",
      "Epoch 3/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.5717 - loss: 0.6803 - val_accuracy: 0.4305 - val_loss: 0.7045\n",
      "Epoch 4/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5933 - loss: 0.6730 - val_accuracy: 0.5265 - val_loss: 0.6962\n",
      "Epoch 5/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5965 - loss: 0.6710 - val_accuracy: 0.4801 - val_loss: 0.6883\n",
      "Epoch 6/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6029 - loss: 0.6621 - val_accuracy: 0.6192 - val_loss: 0.6699\n",
      "Epoch 7/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.6261 - loss: 0.6560 - val_accuracy: 0.4570 - val_loss: 0.7138\n",
      "Epoch 8/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.6213 - loss: 0.6527 - val_accuracy: 0.5099 - val_loss: 0.6984\n",
      "Epoch 9/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.6501 - loss: 0.6371 - val_accuracy: 0.5530 - val_loss: 0.6550\n",
      "Epoch 10/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6894 - loss: 0.6247 - val_accuracy: 0.5099 - val_loss: 0.7044\n",
      "Epoch 11/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6990 - loss: 0.6241 - val_accuracy: 0.5927 - val_loss: 0.6383\n",
      "Epoch 12/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6990 - loss: 0.6123 - val_accuracy: 0.5497 - val_loss: 0.6499\n",
      "Epoch 13/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.6950 - loss: 0.6139 - val_accuracy: 0.5530 - val_loss: 0.6593\n",
      "Epoch 14/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.7062 - loss: 0.6040 - val_accuracy: 0.5530 - val_loss: 0.6571\n",
      "Epoch 15/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7078 - loss: 0.5956 - val_accuracy: 0.5530 - val_loss: 0.6603\n",
      "Epoch 16/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7190 - loss: 0.5901 - val_accuracy: 0.5927 - val_loss: 0.6323\n",
      "Epoch 17/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7166 - loss: 0.5850 - val_accuracy: 0.5563 - val_loss: 0.6559\n",
      "Epoch 18/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7318 - loss: 0.5721 - val_accuracy: 0.5861 - val_loss: 0.6429\n",
      "Epoch 19/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7262 - loss: 0.5785 - val_accuracy: 0.5795 - val_loss: 0.6352\n",
      "Epoch 20/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7310 - loss: 0.5600 - val_accuracy: 0.5530 - val_loss: 0.6941\n",
      "Epoch 21/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7294 - loss: 0.5701 - val_accuracy: 0.6060 - val_loss: 0.6354\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Fold 4 Accuracy: 59.27%\n",
      "\n",
      "--- Training Fold 5 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.4820 - loss: 0.7191 - val_accuracy: 0.6167 - val_loss: 0.6833\n",
      "Epoch 2/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5172 - loss: 0.6911 - val_accuracy: 0.4900 - val_loss: 0.6866\n",
      "Epoch 3/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5508 - loss: 0.6856 - val_accuracy: 0.5233 - val_loss: 0.6807\n",
      "Epoch 4/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5508 - loss: 0.6804 - val_accuracy: 0.6333 - val_loss: 0.6535\n",
      "Epoch 5/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5811 - loss: 0.6774 - val_accuracy: 0.6967 - val_loss: 0.6463\n",
      "Epoch 6/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5795 - loss: 0.6676 - val_accuracy: 0.7000 - val_loss: 0.6252\n",
      "Epoch 7/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6115 - loss: 0.6590 - val_accuracy: 0.7200 - val_loss: 0.6262\n",
      "Epoch 8/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6243 - loss: 0.6508 - val_accuracy: 0.6467 - val_loss: 0.6069\n",
      "Epoch 9/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6163 - loss: 0.6515 - val_accuracy: 0.6667 - val_loss: 0.6277\n",
      "Epoch 10/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6315 - loss: 0.6414 - val_accuracy: 0.6333 - val_loss: 0.6390\n",
      "Epoch 11/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6411 - loss: 0.6300 - val_accuracy: 0.6467 - val_loss: 0.6389\n",
      "Epoch 12/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6355 - loss: 0.6300 - val_accuracy: 0.6333 - val_loss: 0.6374\n",
      "Epoch 13/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6507 - loss: 0.6237 - val_accuracy: 0.6533 - val_loss: 0.6434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Fold 5 Accuracy: 64.67%\n",
      "\n",
      "Final Average TCN Accuracy: 59.42%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "# ==========================================\n",
    "# 1. PREPROCESSING CONFIGURATION\n",
    "# ==========================================\n",
    "SENSOR_DIR = \"C:\\\\DumbStuff\\\\epf study\\\\Meta-Elasto\\\\els\\\\meta\\\\Elastography_rawdata\\\\oldcode\\\\\"\n",
    "FS = 2000          # Sampling Frequency\n",
    "LOWCUT = 10        # Remove motion artifacts\n",
    "HIGHCUT = 450      # Remove high-freq electronic noise\n",
    "MAX_LEN = 2000     # Time steps\n",
    "CHANNELS = 18      # F1 to F18\n",
    "\n",
    "def bandpass_filter(data):\n",
    "    \"\"\"Clean the signal to highlight biological vibrations.\"\"\"\n",
    "    nyq = 0.5 * FS\n",
    "    low = LOWCUT / nyq\n",
    "    high = HIGHCUT / nyq\n",
    "    b, a = butter(4, [low, high], btype='band')\n",
    "    # Apply filter across the time axis (axis 0)\n",
    "    return filtfilt(b, a, data, axis=0)\n",
    "\n",
    "# ==========================================\n",
    "# 2. DATA MERGING & CLEANING\n",
    "# ==========================================\n",
    "df_pre = pd.read_csv(\"label-pre.csv\"); df_pre['Time'] = 'PRE'\n",
    "df_post = pd.read_csv(\"label-post.csv\"); df_post['Time'] = 'POST'\n",
    "df_fup = pd.read_csv(\"label-fup.csv\"); df_fup['Time'] = 'FOLLOWUP'\n",
    "df_clinical = pd.concat([df_pre, df_post, df_fup], axis=0, ignore_index=True)\n",
    "\n",
    "df_mapping = pd.read_excel(\"meta/measured_with_elastograph_patients.xlsx\")\n",
    "df_mapping.columns = df_mapping.columns.str.strip()\n",
    "\n",
    "df_master = pd.merge(df_mapping, df_clinical, on=['ID', 'Time'], how='inner')\n",
    "df_master = df_master.dropna(subset=['Target_Metabolic_Disease', 'Sex', 'Age', 'Waist_Circum_mean'])\n",
    "\n",
    "# Standardize Metadata\n",
    "meta_cols = ['Sex', 'Age', 'Waist_Circum_mean']\n",
    "scaler = StandardScaler()\n",
    "df_master[meta_cols] = scaler.fit_transform(df_master[meta_cols])\n",
    "\n",
    "# ==========================================\n",
    "# 3. DATA LOADING FUNCTION\n",
    "# ==========================================\n",
    "def load_patient_data(dataframe):\n",
    "    X_sig, X_meta, Y, groups = [], [], [], []\n",
    "    \n",
    "    for _, row in dataframe.iterrows():\n",
    "        p_num_str = str(int(row['N_PACIENT'])).zfill(4)\n",
    "        files = glob.glob(os.path.join(SENSOR_DIR, f\"in_test_{p_num_str}_*.csv\"))\n",
    "        \n",
    "        for f in files:\n",
    "            try:\n",
    "                df_sig = pd.read_csv(f)\n",
    "                # Select F1-F18 columns\n",
    "                signal = df_sig.filter(regex='^F\\d+').fillna(0).values\n",
    "                \n",
    "                # Apply Filter\n",
    "                signal = bandpass_filter(signal)\n",
    "                \n",
    "                # Fix Length\n",
    "                if len(signal) > MAX_LEN:\n",
    "                    signal = signal[:MAX_LEN, :]\n",
    "                else:\n",
    "                    signal = np.pad(signal, ((0, MAX_LEN - len(signal)), (0, 0)), 'constant')\n",
    "                \n",
    "                # Normalize Signal (Z-score)\n",
    "                signal = (signal - np.mean(signal)) / (np.std(signal) + 1e-8)\n",
    "                \n",
    "                X_sig.append(signal)\n",
    "                X_meta.append(row[meta_cols].values)\n",
    "                Y.append(row['Target_Metabolic_Disease'])\n",
    "                groups.append(row['ID'])\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    return np.array(X_sig, dtype='float32'), np.array(X_meta, dtype='float32'), \\\n",
    "           np.array(Y, dtype='int32'), np.array(groups)\n",
    "\n",
    "# ==========================================\n",
    "# 4. TCN MODEL ARCHITECTURE (Keras Functional API)\n",
    "# ==========================================\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def residual_block(x, dilation_rate, nb_filters, kernel_size):\n",
    "    prev_x = x\n",
    "\n",
    "    # Main path: length-preserving conv\n",
    "    conv = layers.Conv1D(\n",
    "        filters=nb_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        dilation_rate=dilation_rate,\n",
    "        padding='same',      # keep time length\n",
    "        activation='relu'\n",
    "    )(x)\n",
    "\n",
    "    # Skip path: only match channels, keep same length\n",
    "    if prev_x.shape[-1] != nb_filters:\n",
    "        prev_x = layers.Conv1D(\n",
    "            filters=nb_filters,\n",
    "            kernel_size=1,\n",
    "            padding='same'    # also length-preserving\n",
    "        )(prev_x)\n",
    "\n",
    "    out = layers.Add()([prev_x, conv])\n",
    "    out = layers.Activation('relu')(out)\n",
    "    return out\n",
    "\n",
    "def build_tcn_model():\n",
    "    # Input 1: Signal [Time steps, Channels]\n",
    "    sig_input = Input(shape=(MAX_LEN, CHANNELS))\n",
    "    \n",
    "    # TCN Layers (Dilated Convolutions)\n",
    "    x = sig_input\n",
    "    for d in [1, 2, 4, 8, 16]: # Increasing Dilation allows \"Wide View\"\n",
    "        x = residual_block(x, dilation_rate=d, nb_filters=32, kernel_size=3)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Input 2: Metadata [Sex, Age, Waist]\n",
    "    meta_input = Input(shape=(3,))\n",
    "    m = layers.Dense(16, activation='relu')(meta_input)\n",
    "    \n",
    "    # Fusion\n",
    "    merged = layers.Concatenate()([x, m])\n",
    "    \n",
    "    dense = layers.Dense(32, activation='relu')(merged)\n",
    "    dense = layers.Dropout(0.4)(dense)\n",
    "    output = layers.Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = models.Model(inputs=[sig_input, meta_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ==========================================\n",
    "# 5. CROSS-VALIDATION LOOP\n",
    "# ==========================================\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "patient_ids = df_master['ID'].values\n",
    "fold_accuracies = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(df_master, groups=patient_ids)):\n",
    "    print(f\"\\n--- Training Fold {fold+1} ---\")\n",
    "    \n",
    "    # Load data for this fold\n",
    "    X_sig_train, X_meta_train, y_train, _ = load_patient_data(df_master.iloc[train_idx])\n",
    "    X_sig_val, X_meta_val, y_val, _ = load_patient_data(df_master.iloc[val_idx])\n",
    "    \n",
    "    model = build_tcn_model()\n",
    "    \n",
    "    # Early stopping prevents the model from memorizing noise\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    model.fit(\n",
    "        [X_sig_train, X_meta_train], y_train,\n",
    "        validation_data=([X_sig_val, X_meta_val], y_val),\n",
    "        epochs=50,\n",
    "        batch_size=16,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    probs = model.predict([X_sig_val, X_meta_val])\n",
    "    preds = (probs > 0.5).astype(int)\n",
    "    acc = accuracy_score(y_val, preds)\n",
    "    fold_accuracies.append(acc)\n",
    "    print(f\"Fold {fold+1} Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nFinal Average TCN Accuracy: {np.mean(fold_accuracies)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0c1ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
